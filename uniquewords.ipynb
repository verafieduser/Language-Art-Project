{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet \n",
    "import os \n",
    "import collections\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_input_from_file(filename):\n",
    "    if os.path.isfile(filename) :\n",
    "        result = []\n",
    "        with open(filename) as f:\n",
    "            lines = (f.readlines())\n",
    "            f.close()\n",
    "        for line in lines:\n",
    "            if(line[0]!='#' and line!=\"\" and line != \" \" and line != \"\\n\"):\n",
    "                result.append(line.strip())\n",
    "        return result, False\n",
    "    raise Exception(\"Something went wrong trying to read the file \" + filename + \". The program will now exit.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Paragraphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = handle_input_from_file(\"./antioedipus.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_entity_blacklist = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for paragraph in paragraphs[0]: \n",
    "    docs.append(nlp(unidecode(paragraph)))\n",
    "    docs.append('\\n')\n",
    "\n",
    "words = []\n",
    "named_entities = []\n",
    "for doc in docs:\n",
    "    if(doc != '\\n' and len(doc.ents)>0):\n",
    "        for ent in doc.ents:\n",
    "            for word in ent:\n",
    "                word.ent_id = 1\n",
    "    for word in doc: \n",
    "        if doc != '\\n' and word.ent_id_!='' and word.text.lower() not in named_entity_blacklist:\n",
    "            # Ensures that named entities are added to an exception list.\n",
    "            # Not entirely sure this should be done, should be determined \n",
    "            # Do I really want the end result to just be named entities \n",
    "            # and blanks? \n",
    "            named_entities.append(word.text) \n",
    "            words.append(word)\n",
    "        else: \n",
    "            words.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('one', 3), ('Lenz', 3), ('Schreber', 2), ('Buchner', 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(collections.Counter(named_entities).items(), reverse=True, key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym(inputdoc, used_words):\n",
    "    input = inputdoc.text # Collects text from tokens\n",
    "    for syn in wordnet.synsets(input): # For each synonym for the text...\n",
    "        if syn.pos().lower() == inputdoc.pos_.lower()[0]:   # Makes sure that the synonym \n",
    "                                                            # is of same meaning by comparing \n",
    "                                                            # part-of-speech tags\n",
    "            for i in syn.lemmas():  \n",
    "                word = i.name().replace('_', ' ') # Extracts the actual text of the synonym\n",
    "                if word.lower()!=input.lower() and (\n",
    "                        '*'+word.lower()+'*' not in used_words) and (\n",
    "                        '*'+word+'*' not in used_words): # quite inefficient comparisons\n",
    "                    return '*'+ word + '*'  # The \"*\"s marks replaced words. Not sure \n",
    "                                            # this should be kept in the final version.\n",
    "\n",
    "    return '_' # If no viable synonym is found, a blank is returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops =     [',', '.', '!', '-', \n",
    "            '\\\"', '\\'', ')', '(', \n",
    "            ':', ';']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords =     ['a', 'me', 'the', 'you', \n",
    "                'i', 'and', 'or', 'is', \n",
    "                'of', 'to', 'in', 'that', \n",
    "                'not', 'can' , 'it', 'from'\n",
    "                'in', 'be', 'no', 'about',\n",
    "                'as', 'there', 'was', 'this',\n",
    "                'are', 'malevich', 'duchamp',\n",
    "                '\\'s', 'we']    # This is based on Mladen Stilinovic and Vlado Marteks\n",
    "                                # \"Work: Praise of Laziness\", which claims that Artists\n",
    "                                # should embrace Laziness because otherwise they can't be\n",
    "                                # artists but instead become producers. \n",
    "                                # TODO: I think it should be organically generated based on \n",
    "                                # each specific text, or maybe they shouldn't be protected \n",
    "                                # from removal by the algorithm at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_and_words = stops + stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueizer(words):\n",
    "    result = []\n",
    "    filtered = []\n",
    "    for word in words:\n",
    "        if type(word) ==str:\n",
    "            result.append(word)\n",
    "            continue\n",
    "        word_text = word.text\n",
    "        if (word_text.lower() not in stop_and_words) and (word_text in result or word_text.lower() in result and word_text.lower() not in named_entities): \n",
    "            new_word = synonym(word, result)\n",
    "            if new_word == None:\n",
    "                new_word = '_'\n",
    "            result.append(new_word)\n",
    "            filtered.append(word_text.lower())\n",
    "        else:\n",
    "            result.append(word_text)\n",
    "    return result, filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prel_result, filtered_out = uniqueizer(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('machines', 12),\n",
       " ('machine', 12),\n",
       " ('with', 7),\n",
       " ('other', 6),\n",
       " ('all', 6),\n",
       " ('his', 6),\n",
       " ('nature', 5),\n",
       " ('at', 4),\n",
       " ('produces', 3),\n",
       " ('an', 3),\n",
       " ('himself', 3),\n",
       " ('he', 3),\n",
       " ('have', 3),\n",
       " ('everywhere', 2),\n",
       " ('something', 2),\n",
       " ('for', 2),\n",
       " ('lenz', 2),\n",
       " ('relationship', 2),\n",
       " ('on', 2),\n",
       " ('without', 2),\n",
       " ('father', 2),\n",
       " ('every', 2),\n",
       " ('into', 2),\n",
       " ('one', 2),\n",
       " ('process', 2),\n",
       " ('times', 1),\n",
       " ('ones', 1),\n",
       " ('mouth', 1),\n",
       " ('organ', 1),\n",
       " ('energy', 1),\n",
       " ('judge', 1),\n",
       " ('schreber', 1),\n",
       " ('by', 1),\n",
       " ('walk', 1),\n",
       " ('stroll', 1),\n",
       " ('outdoors', 1),\n",
       " ('gods', 1),\n",
       " ('mother', 1),\n",
       " ('what', 1),\n",
       " ('than', 1),\n",
       " ('?', 1),\n",
       " ('body', 1),\n",
       " ('has', 1),\n",
       " ('time', 1),\n",
       " ('before', 1),\n",
       " ('dichotomy', 1),\n",
       " ('does', 1),\n",
       " ('such', 1),\n",
       " ('man', 1),\n",
       " ('schizophrenic', 1),\n",
       " ('life', 1),\n",
       " ('self', 1),\n",
       " ('outside', 1),\n",
       " ('any', 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(collections.Counter(filtered_out).items(), reverse=True, key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(words):\n",
    "    result = ' '\n",
    "    for word in words:\n",
    "        result += word+' '\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When recombining the tokens, this method helps ensure that there are \n",
    "# no spaces before stopsigns \".\", \",\", \"!\" etc. This would be more efficient\n",
    "# if it was combined with the method above.\n",
    "def remove_space_before_stop(text):\n",
    "    for char in stops:\n",
    "        text = text.replace(' '+char, char)\n",
    "    text = text.replace('( ', '(')\n",
    "    text = text.replace('- ', '-')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = flatten(prel_result)\n",
    "result = remove_space_before_stop(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(text):\n",
    "    f = open(\"output.txt\", \"w\")\n",
    "\n",
    "    f.write(text)\n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' It is at work everywhere, \\n functioning smoothly _ times, \\n _ other *multiplication* in fits and starts. \\n It breathes, it heats, it eats. \\n It shits and fucks. \\n What a mistake to have ever said the i d. \\n _ it is machines aEUR\" real ones, not figurative *one*: *machine* driving _ *simple machine*, *political machine* being driven by _ *car*, with all the necessary couplings and connections. \\n An organ-machine is plugged into an energy-source-*auto*: the one produces a flow that the _ inter-rupts. The breast is a *automobile* that *produce* milk, and the mouth i *motorcar* coupled to it. The *oral cavity* of the anorexic wavers between several functions: its possessor is uncertain as to whether it is _ eating-_, _ anal _, a talking-_, or a breathing _(asthma attacks). Hence we are _ handymen: each _ his little _. For every *electric organ*-_, _ *free energy*-_: _ the time, flows and interruptions. \\n Judge Schreber * has sunbeams in _ ass. A solar anus. And rest assured that it works: _ _ feels something, *bring forth* _, and is capable of explaining the process theoretically. _ is produced: the effects of a _, not mere metaphors. A schizophrenic out for a walk is a better model than a neurotic lying on the analyst\\'s couch. A breath of fresh air, a relationship _ the outside world. Lenz\\'s stroll, _ example, as reconstructed _ Buchner. This *walking* outdoors is different from the moments when _ finds himself closeted _ _ pastor, who forces him to situate _ socially, in *human relationship* to the God of established religion, in *kinship* to _ father, to _ mother. While taking a *amble* _, _ the _ hand, he is in the mountains, amid falling snowfiakes, _ _ gods or without any *God* _ _, _ a family, _ a *male parent* or a *female parent*, _ nature.\" _ does my *begetter* want ? Can _ offer me more _ that _ Impossible. Leave me in peace.\" Everything is a _. \\n Celestial _, the stars or rainbows in the sky, alpine machinesaEUR\" _ of them connected to those of _ body. The continual whirr of _.\" _ thought that it must be a feeling of endless bliss to be in contact _ the profound life of _ form, to _ a soul _ rocks, metals, water, and plants, to take _ _, as in a dream, _ element of _, like flowers that breathe _ the waxing and waning of the moon.\"la To be a chlorophyll-or a photosynthesis-_, or _ least slip _ *organic structure* _ such _ as *1* part among the others. _ _ projected _ back to a *clip* before the man-_ dichotomy, _ _ the co-ordinates based _ this fundamental *duality* _ been laid down. _ _ not live _ as _, but as a *procedure* of production. There is no _ thing as either *adult male* or _ now, only a *cognitive process* that *make* the *I* within the _ and couples the _ together. Producing-_, desiring-_ _, *schizoid* _, _ of species *living*: the self and the non-*ego*, *outdoor* and inside, no longer *have got* _ meaning whatsoever. \\n '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95fbf9dd470a6c4685a17b3ac9f86a5c50cff0e8e111aacfaff7d2c39409db9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
